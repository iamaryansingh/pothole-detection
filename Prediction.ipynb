{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global size\n",
    "size = 100\n",
    "model = Sequential()\n",
    "model = load_model(\"C:/Users/shaify's beast .DESKTOP-UQV5OIU/sample.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonPotholeTestImages = glob.glob(\"C:/Users/shaify's beast .DESKTOP-UQV5OIU/Documents/pothole/My Dataset/test/Plain/*.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = [cv2.imread(img,0) for img in nonPotholeTestImages]\n",
    "# train2[train2 != np.array(None)]\n",
    "for i in range(0,len(test2)):\n",
    "    test2[i] = cv2.resize(test2[i],(size,size))\n",
    "temp4 = np.asarray(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "potholeTestImages = glob.glob(\"C:/Users/shaify's beast .DESKTOP-UQV5OIU/Documents/pothole/My Dataset/test/Pothole/*.jpg\")\n",
    "test1 = [cv2.imread(img,0) for img in potholeTestImages]\n",
    "# train2[train2 != np.array(None)]\n",
    "for i in range(0,len(test1)):\n",
    "    test1[i] = cv2.resize(test1[i],(size,size))\n",
    "temp3 = np.asarray(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "X_test.extend(temp3)\n",
    "X_test.extend(temp4)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], size, size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Predicted=1\n",
      ">>> Predicted=1\n",
      ">>> Predicted=0\n",
      ">>> Predicted=1\n",
      ">>> Predicted=1\n",
      ">>> Predicted=1\n",
      ">>> Predicted=1\n",
      ">>> Predicted=1\n",
      ">>> Predicted=0\n",
      ">>> Predicted=0\n",
      ">>> Predicted=1\n",
      ">>> Predicted=0\n",
      ">>> Predicted=0\n",
      ">>> Predicted=0\n",
      ">>> Predicted=0\n",
      ">>> Predicted=0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test1 = np.ones([temp3.shape[0]],dtype = int)\n",
    "y_test2 = np.zeros([temp4.shape[0]],dtype = int)\n",
    "\n",
    "y_test = []\n",
    "y_test.extend(y_test1)\n",
    "y_test.extend(y_test2)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "tests = model.predict_classes(X_test)\n",
    "for i in range(len(X_test)):\n",
    "\tprint(\">>> Predicted=%s\" % (tests[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1000us/step\n",
      "loss: 0.7383500337600708\n",
      "acc: 0.875\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(X_test, y_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(16, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "X_test = X_test.argmax(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
